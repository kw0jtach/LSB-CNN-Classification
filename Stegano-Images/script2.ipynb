{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6097546a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "class CustomCNNFusion(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),  # [B, 32, 224, 224]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),                             # [B, 32, 112, 112]\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),                             # [B, 64, 56, 56]\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),                             # [B, 128, 28, 28]\n",
    "        )\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128 * 28 * 28 + 8, 128),  # +8 pour les features statistiques\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 2)  # 2 classes : normal / steg\n",
    "        )\n",
    "\n",
    "    def forward(self, x_img, x_stats):\n",
    "        x = self.cnn(x_img)\n",
    "        x = self.flatten(x)              # [B, 128 * 28 * 28]\n",
    "        x = torch.cat((x, x_stats), dim=1)  # fusion avec features stats\n",
    "        return self.fc(x)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "class ResStatFusion(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        base_model = models.resnet18(pretrained=True)\n",
    "        self.cnn = nn.Sequential(*list(base_model.children())[:-1])  # [B, 512, 1, 1]\n",
    "\n",
    "        self.stat_fc = nn.Sequential(\n",
    "            nn.Linear(8, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.final_fc = nn.Sequential(\n",
    "            nn.Linear(512 + 64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, image, stat_feats):\n",
    "        # CNN branch\n",
    "        cnn_feat = self.cnn(image).squeeze()  # [B, 512]\n",
    "        if cnn_feat.dim() == 1:\n",
    "            cnn_feat = cnn_feat.unsqueeze(0)\n",
    "\n",
    "        # MLP branch\n",
    "        stat_feat = self.stat_fc(stat_feats)  # [B, 64]\n",
    "\n",
    "        fusion = torch.cat((cnn_feat, stat_feat), dim=1)  # [B, 576]\n",
    "        out = self.final_fc(fusion)\n",
    "        return out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88128a33",
   "metadata": {},
   "source": [
    "Ce dataset retourne trois √©l√©ments :\n",
    "\n",
    "üì∑ L‚Äôimage transform√©e (Tensor)\n",
    "\n",
    "üìä Les features statistiques extraits de cette image\n",
    "\n",
    "üè∑Ô∏è Le label (0 = normal, 1 = steg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d17af77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from scipy.stats import kurtosis, skew\n",
    "from torchvision import transforms\n",
    "\n",
    "class FusionFeatureDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        root_dir: dossier contenant deux sous-dossiers 'normal' et 'stego'\n",
    "        transform: transformations √† appliquer √† l'image (ex: resize, normalize)\n",
    "        \"\"\"\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "\n",
    "        for label_name in os.listdir(root_dir):\n",
    "            label_dir = os.path.join(root_dir, label_name)\n",
    "            label = 0 if label_name.lower() == 'normal' else 1\n",
    "\n",
    "            for img_name in os.listdir(label_dir):\n",
    "                img_path = os.path.join(label_dir, img_name)\n",
    "                self.image_paths.append(img_path)\n",
    "                self.labels.append(label)\n",
    "\n",
    "    def extract_stat_features(self, img):\n",
    "        \"\"\"\n",
    "        Extrait 8 features statistiques d'une image grayscale\n",
    "        \"\"\"\n",
    "        img_gray = img.convert('L')\n",
    "        data = np.asarray(img_gray).flatten()\n",
    "\n",
    "        std = np.std(data)\n",
    "        range_val = np.max(data) - np.min(data)\n",
    "        median = np.median(data)\n",
    "        geo_median = np.exp(np.mean(np.log(data + 1e-5)))  # +eps pour log(0)\n",
    "        skewness = skew(data)\n",
    "        kurt = kurtosis(data)\n",
    "        d1 = np.diff(data)\n",
    "        d2 = np.diff(d1)\n",
    "        var0 = np.var(data)\n",
    "        var1 = np.var(d1)\n",
    "        var2 = np.var(d2)\n",
    "        mobility = np.sqrt(var1 / var0)\n",
    "        complexity = np.sqrt((var2 / var1) - (var1 / var0))\n",
    "\n",
    "        return torch.tensor([std, range_val, median, geo_median, skewness, kurt, mobility, complexity], dtype=torch.float32)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.image_paths[index]\n",
    "        label = self.labels[index]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        stat_features = self.extract_stat_features(img)\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, stat_features, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6e9b62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kilio\\AppData\\Local\\Temp\\ipykernel_19908\\2360728561.py:47: RuntimeWarning: invalid value encountered in sqrt\n",
      "  complexity = np.sqrt((var2 / var1) - (var1 / var0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32, 8])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "class RandomRotation:\n",
    "    def __call__(self, img):\n",
    "        angles = [0, 90, 180, 270]\n",
    "        angle = random.choice(angles)\n",
    "        return TF.rotate(img, angle)\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    #RandomRotation(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], \n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "train_dir = 'stegoimagesdataset/train/train/'\n",
    "val_dir = 'stegoimagesdataset/val/val/'\n",
    "test_dir = 'stegoimagesdataset/test/test/'\n",
    "\n",
    "train_dataset = FusionFeatureDataset(root_dir=train_dir, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "val_dataset = FusionFeatureDataset(root_dir=val_dir, transform=transform)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "test_dataset = FusionFeatureDataset(root_dir=test_dir, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Exemple de batch :\n",
    "for img_batch, stat_batch, label_batch in train_loader:\n",
    "    print(img_batch.shape)       # [32, 3, 224, 224]\n",
    "    print(stat_batch.shape)      # [32, 8]\n",
    "    print(label_batch.shape)     # [32]\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bb1e7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f532fb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, val_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, stat_feats, labels in val_loader:\n",
    "            images, stat_feats, labels = images.to(device), stat_feats.to(device), labels.to(device)\n",
    "            outputs = model(images, stat_feats)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    acc = correct / total * 100\n",
    "    print(f\"Validation Accuracy: {acc:.2f}%\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f8486d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, num_epochs, device, patience, save_path):\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, stat_feats, labels in train_loader:\n",
    "            images, stat_feats, labels = images.to(device), stat_feats.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images, stat_feats)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * labels.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / total\n",
    "        epoch_acc = correct / total * 100\n",
    "        print(f\"[Train] Epoch {epoch+1}/{num_epochs} | Loss: {epoch_loss:.4f} | Accuracy: {epoch_acc:.2f}%\")\n",
    "\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for val_images, val_feats, val_labels in val_loader:\n",
    "                val_images, val_feats, val_labels = val_images.to(device), val_feats.to(device), val_labels.to(device)\n",
    "                val_outputs = model(val_images, val_feats)\n",
    "                _, val_pred = torch.max(val_outputs, 1)\n",
    "                val_correct += (val_pred == val_labels).sum().item()\n",
    "                val_total += val_labels.size(0)\n",
    "\n",
    "        val_acc = val_correct / val_total * 100\n",
    "        print(f\"[Validation] Accuracy: {val_acc:.2f}%\")\n",
    "\n",
    "        # === Early Stopping & Best Model Saving ===\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            epochs_without_improvement = 0\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(\"Best model saved.\")\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            print(f\"No improvement. ({epochs_without_improvement}/{patience})\")\n",
    "\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    print(f\"Training finished. Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad91033a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomCNNFusion()\n",
    "model2 = ResStatFusion()\n",
    "trained_model = train_model(model, train_loader, val_loader, num_epochs=30, device=device, patience=5, save_path='best_model_CNNFUSION.pth')\n",
    "trained_model2 = train_model(model2, train_loader, val_loader, num_epochs=30, device=device, patience=5, save_path='best_model_ResStatFusion.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4adb617",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def test_model(model_class, test_loader, model_path, device):\n",
    "    model = model_class().to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, stat_feats, labels in test_loader:\n",
    "            images, stat_feats, labels = images.to(device), stat_feats.to(device), labels.to(device)\n",
    "            outputs = model(images, stat_feats)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    labels_names = ['Normal (0)', 'Stego (1)']\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels_names, yticklabels=labels_names)\n",
    "    plt.xlabel('Pr√©dit')\n",
    "    plt.ylabel('Vrai')\n",
    "    plt.title('Matrice de confusion')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Rapport de classification :\")\n",
    "    print(classification_report(y_true, y_pred, target_names=labels_names))\n",
    "\n",
    "#test_model(CustomCNNFusion, test_loader, 'best_model_CNNFUSION.pth', device)\n",
    "#test_model(ResStatFusion, test_loader, 'best_model_ResStatFusion.pth', device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
